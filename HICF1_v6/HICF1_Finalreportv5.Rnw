\documentclass[a4paper,11pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage[margin=1.5cm]{geometry}
\usepackage{lscape}

\title{HICF1 -  Final Report v4}
\author{Dr. Susanne Weller}
\date{\today}

\begin{document}
\SweaveOpts{concordance=TRUE}

\maketitle
\tableofcontents
\section{Univariate Analysis}
<<data, echo=FALSE>>=
setwd("/home/andreas/suska/work/01_HICF1/HICF1_sub1/trunk/HICF1_v6")
genclinv6 <- read.table("239_for_Suska_040714.txt", header=TRUE, sep="\t", strip.white = TRUE, na.strings=c("Unknown"," sample not taken", "Missing", "Unable to assess", "Early death", "Withdrew from follow-up data collection", "Equivocal"))
#names(genclinv6)[names(genclinv6)=="TP53_mut_lowVAF"] <- "TP53_mut"

#calculate TP53with low VAF
samples_lowVAF <- c("ARC079", "ARC304", "ADM012", "ARC017", "ARC091", "ARC393", "ARC592", "ARC683")
genclinv6$TP53_lowVAF <- as.factor(ifelse(genclinv6$ID %in% samples_lowVAF, "1", "0"))
genclinv6[,c(2:43, 46, 60)] <- lapply(genclinv6[,c(2:43, 46, 60)], as.factor)
genclinv6 <- genclinv6[,-c(1, 50, 51, 54,57:58)]

#calculate clones and CNAs as factors:
#genclinv6$clones_cutoff0 <- as.factor(ifelse(genclinv6$Subclones==0, "0", "1"))
#genclinv6$CNAs_cutoff6 <- as.factor(ifelse(genclinv6$Total_num_CNAs <= 6, "low", "high"))

#correct levels for vh_mutation_status and Binet
genclinv6$vh_mutation_status <- as.factor(ifelse(genclinv6$vh_mutation_status=="Biclonal"|genclinv6$vh_mutation_status=="Mutated", "mutated", "unmutated"))

genclinv6$Binet <- as.factor(ifelse(genclinv6$Binet=="A progressive" | genclinv6$Binet=="B", "A_or_B", "C"))

#remove columns with <5% VAFs
genclinv6$TP53_mut_All_VAFs <- NULL
#genclinv6$TP53_lowVAF <- NULL
#rename columns
names(genclinv6)[names(genclinv6)=="TP53_biallelic"] <- "TP53_bi"
names(genclinv6)[names(genclinv6)=="ATM_more_than_one_mutation"] <- "ATM_mt1"
names(genclinv6)[names(genclinv6)=="ATM_biallelic"] <- "ATM_bi"
names(genclinv6)[names(genclinv6)=="BIRC3_biallelic"] <- "BIRC3_bi"
names(genclinv6)[names(genclinv6)=="X11q_monoallelic"] <- "X11q_mono"
names(genclinv6)[names(genclinv6)=="ATM_monoallelic"] <- "ATM_mono"
names(genclinv6)[names(genclinv6)=="BIRC3_monoallelic"] <- "BIRC3_mono"
names(genclinv6)[names(genclinv6)=="X6.q_del_homozygous"] <- "X6qdel_homo"
names(genclinv6)[names(genclinv6)=="X13q_del_homozygous"] <- "X13del_homo"
names(genclinv6)[names(genclinv6)=="X13q_del_incl_RB1"] <- "X13qdelRB1"
names(genclinv6)[names(genclinv6)=="X13q_sole_abnorm_Oxdefined"] <- "X13q_Ox"
names(genclinv6)[names(genclinv6)=="X13q_sole_abnormality_Rossi"] <- "X13q_Rossi"
names(genclinv6)[names(genclinv6)=="TP53_mut_largerthan5VAF"] <- "TP53_mut"


@
Note that TP53\_mut are only mutation with >5\%VAF! Univariate p-values change dramatically if you add more variables, this is due to the multiple testing problem. I have used False Discovery Rate, currently the least stringent correction method that was specifically designed for genetics.
<<Univariates, echo=FALSE, eval=TRUE>>=
source("/home/andreas/suska/work/01_HICF1/HICF1_sub1/trunk/HICF1_v6/Univariateanalysis.R")
univariate_variables <- c( "TP53_mut", "TP53_bi", "ATM_bi", "ATM_del", "ATM_mono", "BIRC3_bi", "BIRC3_del", "BIRC3_mono", "SAMHD1_ALL", "Trisomy_12", "NOTCH1_mut", "SF3B1_mut", "Subclones", "Total_num_CNAs", "MRD", "X11q_mono", "TP53_lowVAF")

genclinv6.univar <- genclinv6[colnames(genclinv6) %in% univariate_variables]
genclinv6.univar.pvalues <- lapply(genclinv6.univar[,-16], univariate.pvalue.genclinv6)
genclinv6.univar.pvalues <- unlist(genclinv6.univar.pvalues)
genclinv6.univar.pvalues <- as.data.frame(genclinv6.univar.pvalues)
colnames(genclinv6.univar.pvalues) <- "p"
#This rounds the p-value
genclinv6.univar.pvalues$p <- round(genclinv6.univar.pvalues$p, 3)
#This corrects the p-value
genclinv6.univar.pvalues$sig <- mapply(significance, genclinv6.univar.pvalues$p)
genclinv6.univar.pvalues$corr.p <- round(p.adjust(genclinv6.univar.pvalues$p, method="fdr"),3)

#This gives the significant levels
genclinv6.univar.pvalues$sig.corr <- mapply(significance, genclinv6.univar.pvalues$corr.p)

#This gives the n in each group
genclinv6.univar.pvalues$MRDpos_0 <- (round(as.integer(unlist(lapply(genclinv6.univar[,-16], univariate.n.MRDpos.0)))/209,2))*100
genclinv6.univar.pvalues$MRDpos_0 <- paste(genclinv6.univar.pvalues$MRDpos_0, "%", sep="")
genclinv6.univar.pvalues$MRDneg_0 <- round(as.integer(unlist(lapply(genclinv6.univar[,-16], univariate.n.MRDneg.0)))/209, 2)*100
genclinv6.univar.pvalues$MRDneg_0 <- paste(genclinv6.univar.pvalues$MRDneg_0, "%", sep="")
genclinv6.univar.pvalues$MRDpos_1 <- round(as.integer(unlist(lapply(genclinv6.univar[,-16], univariate.n.MRDpos.1)))/209,2)*100
genclinv6.univar.pvalues$MRDpos_1 <- paste(genclinv6.univar.pvalues$MRDpos_1, "%", sep="")
genclinv6.univar.pvalues$MRDneg_1 <- round(as.integer(unlist(lapply(genclinv6.univar[,-16], univariate.n.MRDneg.1)))/209,2)*100
genclinv6.univar.pvalues$MRDneg_1 <- paste(genclinv6.univar.pvalues$MRDneg_1, "%", sep="")

#This gives the test that was used:
#genclinv6.univar.pvalues$testused <- unlist(lapply(genclinv6.univar[,-19], univariate.testused))

genclinv6.univar.pvalues <- genclinv6.univar.pvalues[order(row.names(genclinv6.univar.pvalues)),]
genclinv6.univar.pvalues <- genclinv6.univar.pvalues[c(1:9, 12:16, 10:11),]

#  write.csv(genclinv6.univar.pvalues, file="/home/andreas/suska/work/01_HICF1/HICF1_sub1/trunk/HICF1_v6/Univariatepvalues_SW_17072014.csv", sep="\t")
@

<<echo=FALSE, results=tex>>=
#RESULT TABLE in a nice format!
library(stargazer)
stargazer(genclinv6.univar.pvalues, summary=FALSE, title="Univariate Analysis against MRD outcome", font.size="tiny",column.sep.width="0p")
@

\section{Associations}
To test for associations, I first counted the number of patients that have a particular mutation, and derived the probablity of having this lesion:\\
Example:\\
8 out of 209 patients have mutation X -> probability estimate for this mutation is 8/209\\
15 out of 209 patients have mutation Y ->  probability estimate for this mutation is 15/209\\
The expected probablity of having both mutations is then 8/209 x 15/209\\

I then compared this expected probability to the observed probability using Exact Binomial Tests. This test is the only one that I could find that can deal with low numbers AND allows for testing agains expected frequencies. Fisher's Exact test is often used that way by constructing the expected frequencies from the expected probabilities, but does not allow for integers, which is a problem with the low numbers we are dealing with.\\
I again used False Discovery Rate to correct the p-values.


<<echo=FALSE, eval=TRUE>>=
#Produce data frame for association calculations:
#add time until diagnosis

#use two for loops to get the column numbers changed!
source("/home/andreas/suska/work/01_HICF1/HICF1_sub1/trunk/HICF1_v6/Association.R")

variables_ass <- c("TP53_mut", "TP53_del", "TP53_cnLOH", "ATM_mut", "ATM_del", "ATM_cnLOH", "BIRC3_mut", "BIRC3_del", "NOTCH1_mut", "SF3B1_mut", "X13q_ALL", "X6q._del_ALL", "Trisomy_12", "Trisomy_18", "Trisomy_19", "XPO1_gain", "SAMHD1_ALL", "MYD88_mut", "MED12mutation", "X8q_ALL", "Subclones", "Total_num_CNAs")

genclinv6.ass <- genclinv6[colnames(genclinv6) %in% variables_ass]
#produce a new data frame that contains variable names as first column
#This makes the first column a list of all the variables used
ass.pvalues <- colnames(genclinv6.ass)
ass.pvalues <- as.data.frame(ass.pvalues)
names(ass.pvalues)[names(ass.pvalues)=="ass.pvalues"] <- "variables"
#This just produces a list of all the variables used to go through in the for loops
variables <- colnames(genclinv6.ass)
for (i in 1:22){
ass.pvalues[variables[i]] <- NA
}
genclinv6.ass$Subclones <- as.numeric(genclinv6.ass$Subclones)
genclinv6.ass$Total_num_CNAs <- as.numeric(genclinv6.ass$Total_num_CNAs)
for (i in 1:22){
  for (j in 1:22){
  ass.pvalues[i, j+1] <- association.pvalue(i, j) 
}
}

ass.pvalues[,c(2:23)] <- lapply(ass.pvalues[,c(2:23)], as.numeric)

ass.pvalues.corrected <- as.matrix(ass.pvalues[, -1]) 
ass.pvalues.corrected <- round(p.adjust(ass.pvalues.corrected, method="fdr"), digits=3)
ass.pvalues.corrected <- split(ass.pvalues.corrected, ceiling(seq_along(ass.pvalues.corrected)/length(ass.pvalues[[1]])))

ass.pvalues[,c(2:23)] <- round(ass.pvalues[,c(2:23)], digits=3)
ass.pvalues.corrected <- as.data.frame(ass.pvalues.corrected)
colnames(ass.pvalues.corrected) <- variables
ass.pvalues.corrected <- cbind(variables, ass.pvalues.corrected)

 #write.csv(ass.pvalues, file="/home/andreas/suska/work/01_HICF1/HICF1_sub1/trunk/HICF1_v6/Associationpvalues_v2.csv", sep="\t")
# write.csv(ass.pvalues.corrected, file="/home/andreas/suska/work/01_HICF1/HICF1_sub1/trunk/HICF1_v6/Associationpvalues_corrected_v2.csv", sep="\t")

@

\begin{landscape}
<<echo=FALSE, results=tex>>=
#RESULT TABLE in a nice format!
library(xtable)
pvaluetable <- xtable(ass.pvalues, caption="Association chart, uncorrected pvalues, Fisher's test")
align(pvaluetable) <- "|r|r|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|"
print(pvaluetable, vline.after = c(1,1), size="tiny", type="latex", rotate.rownames=TRUE, scalebox=0.6, width=10, include.rownames=FALSE)
@

<<echo=FALSE, results=tex>>=
#RESULT TABLE in a nice format!
library(xtable)
corr.pvaluetable <- xtable(ass.pvalues.corrected, caption="Association chart, corrected pvalues, Fisher's test with FDR correction")
align(corr.pvaluetable) <- "|r|r|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|"
print(corr.pvaluetable, vline.after = c(1,1), size="tiny", type="latex", rotate.rownames=TRUE, scalebox=0.6, width=10, include.rownames=FALSE)
@
 \end{landscape}

Odds ratios and p-values for associations between genes are represented in this heatmap. Note that odds ratios 0-1 (the first bar in the colour key) are mutually exclusive, everything else already counts as co-occuring.\\
\emph{Note: Colour key still needs be adjusted to a somewhat funny scale to see this properly.}

<<oddssratio, echo=FALSE, eval=TRUE>>=
source("oddsratio.R")
#This makes an empty data frame with the first line the list of variables used:
ass.oddsratios <- colnames(genclinv6.ass)
ass.oddsratios <- as.data.frame(ass.oddsratios)
names(ass.oddsratios)[names(ass.oddsratios)=="ass.oddsratios"] <- "variables"
for (i in 1:22){
ass.oddsratios[variables[i]] <- NA
}

for (i in 1:22){
  for (j in 1:22){
  ass.oddsratios[i, j+1] <- oddsratio(i, j) 
}
}
@
\begin{landscape}
<<echo=FALSE, results=tex>>=
#RESULT TABLE in a nice format!
library(xtable)
oddsratiotable <- xtable(ass.oddsratios, caption="Odds ratios for association between genes")
align(oddsratiotable) <- "|r|r|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|"
print(oddsratiotable, vline.after = c(1,1), size="tiny", type="latex", rotate.rownames=TRUE, scalebox=0.6, width=10, include.rownames=FALSE)
@
\end{landscape}
\newpage

<<fig=TRUE, echo=FALSE, eval=TRUE, width=9.5>>=

#Produce matrix indicating significance
source("significancelevels.R")
sigstars <- apply(ass.pvalues.corrected[2:23], c(1,2), significancelevels) 

#Remove all odds ratios with insignificant values:
ass.oddsratios.plot <- colnames(genclinv6.ass)
ass.oddsratios.plot <- as.data.frame(ass.oddsratios.plot)
names(ass.oddsratios.plot)[names(ass.oddsratios.plot)=="ass.oddsratios.plot"] <- "variables"
for (i in 1:22){
ass.oddsratios.plot[variables[i]] <- NA
}
source("oddsratio.R")
for (i in 1:22){
  for (j in 1:22){
  if(sigstars[i, j]==""){
    ass.oddsratios.plot[i, j+1] <- NA
  }
  else{
   ass.oddsratios.plot[i, j+1] <- oddsratio(i, j)  
  }  
}
}

association.pvalue(21, 22)
ass.oddsratios.plot[,c(2:23)] <- lapply(ass.oddsratios.plot[,c(2:23)], as.numeric)

# Set variables to row.names
row.names(ass.oddsratios.plot) <- ass.oddsratios.plot$variables
ass.oddsratios.plot$variables <- NULL


#get your own colour scheme
library("RColorBrewer")
oddsratiocolours <- colorRampPalette(c("darkslategrey", "cadetblue3", "cadetblue1", "mediumpurple1", "hotpink", "magenta"))

library("gplots")
heatmap.2((as.matrix(ass.oddsratios.plot, rownames.force=TRUE)), col=oddsratiocolours, scale="none", na.rm=TRUE, key=TRUE, symkey=FALSE, density.info="none", trace="none", cexRow=0.5, xlab="", ylab="", Rowv=FALSE, Colv=FALSE, cexCol = 0.7, sepwidth=c(0.1,0.1), sepcolor="white", rowsep=c(1:22), colsep=c(1:22), na.color="gray94", cellnote=sigstars, notecol="black", main="Association for n=239")


@
\section{Model building - from here, only 209 data points will be used}
% \section{Association on model data}
% This was calculated to see if there are Co-linearities that have to be taken into account for the modelling. There are fewer associations than in the 239 data set, but as you can see from the chart, the associations don't change much.
% <<Model data set, echo=FALSE, eval=TRUE>>=
% model.genclinv6 <-subset(genclinv6, !is.na(genclinv6$MRD))
% #These are the variables that we want for the association chart
% variables_ass <- c("TP53_ALL", "TP53_mut", "TP53_del", "TP53_cnLOH", "ATM_ALL", "ATM_mut", "ATM_del", "ATM_cnLOH", "BIRC3_ALL", "BIRC3_mut", "BIRC3_del", "NOTCH1_mut", "SF3B1_mut", "X13q_ALL", "X6q._del_ALL", "Trisomy_12", "Trisomy_18", "Trisomy_19", "XPO1_gain", "SAMHD1_ALL", "MYD88_mut", "MED12mutation", "X8q_ALL", "Subclones", "Total_num_CNAs")
% model.genclinv6.ass <- model.genclinv6[colnames(model.genclinv6) %in% variables_ass]
% 
% @
% 
% <<Association on model data, echo=FALSE, eval=TRUE>>=
% source("/home/andreas/suska/work/01_HICF1/HICF1_sub1/trunk/HICF1_v6/Association.R")
% #produce a new data frame that contains variable names as first column
% #This makes the first column a list of all the variables used
% model.ass.pvalues <- colnames(model.genclinv6.ass)
% model.ass.pvalues <- as.data.frame(model.ass.pvalues)
% names(model.ass.pvalues)[names(model.ass.pvalues)=="model.ass.pvalues"] <- "variables"
% #This just produces a list of all the variables used to go through in the for loops
% variables <- colnames(model.genclinv6.ass)
% #this should produce the empty data frame
% for (i in 1:25){
% model.ass.pvalues[,variables[i]] <- NA
% }
% model.genclinv6.ass$Subclones <- as.numeric(model.genclinv6.ass$Subclones)
% model.genclinv6.ass$Total_num_CNAs <- as.numeric(model.genclinv6.ass$Total_num_CNAs)
% for (i in 1:25){
%   for (j in 1:25){
%   model.ass.pvalues[i, j+1] <- association.pvalue(i, j) 
% }
% }
% 
% 
% model.ass.pvalues[,c(2:26)] <- lapply(model.ass.pvalues[,c(2:26)], as.numeric)
% 
% model.ass.pvalues.corrected <- as.matrix(model.ass.pvalues[, c(2:26)]) 
% model.ass.pvalues.corrected <- round(p.adjust(model.ass.pvalues.corrected, method="holm"), digits=3)
% model.ass.pvalues.corrected <- split(model.ass.pvalues.corrected, ceiling(seq_along(model.ass.pvalues.corrected)/length(model.ass.pvalues[[1]])))
% 
% model.ass.pvalues[,c(2:26)] <- round(model.ass.pvalues[,c(2:26)], digits=3)
% model.ass.pvalues.corrected <- as.data.frame(model.ass.pvalues.corrected)
% colnames(model.ass.pvalues.corrected) <- variables
% model.ass.pvalues.corrected <- cbind(variables, model.ass.pvalues.corrected)
% 
% # write.csv(model.ass.pvalues, file="/home/andreas/suska/work/01_HICF1/HICF1_sub1/trunk/HICF1_v6/Associationpvalues_model.csv", sep="\t")
% # write.csv(model.ass.pvalues.corrected, file="/home/andreas/suska/work/01_HICF1/HICF1_sub1/trunk/HICF1_v6/Associationpvalues_model_corrected.csv", sep="\t")
% 
% @
% 
% <<oddssratio, echo=FALSE, eval=TRUE>>=
% source("oddsratio.R")
% #This makes an empty data frame with the first line the list of variables used:
% model.ass.oddsratios <- colnames(model.genclinv6.ass)
% model.ass.oddsratios <- as.data.frame(model.ass.oddsratios)
% names(model.ass.oddsratios)[names(model.ass.oddsratios)=="model.ass.oddsratios"] <- "variables"
% for (i in 1:25){
% model.ass.oddsratios[variables[i]] <- NA
% }
% 
% for (i in 1:25){
%   source("oddsratioscale.R")
%   for (j in 1:25){
%   model.ass.oddsratios[i, j+1] <- oddsratioscale(i, j) 
% }
% }
% @
% \begin{landscape}
% <<echo=FALSE, results=tex>>=
% #RESULT TABLE in a nice format!
% library(stargazer)
% stargazer(model.ass.pvalues.corrected, summary=FALSE, title="Corrected p-values for association between genetic lesions, n=209", font.size="tiny", column.sep.width="0p")
% @
% \end{landscape}
% <<fig=TRUE, echo=FALSE, eval=TRUE>>=
% # Set variables to row.names
% row.names(model.ass.oddsratios) <- model.ass.oddsratios$variables
% model.ass.oddsratios$variables <- NULL
% 
% #Produce matrix indicating significance
% source("significancelevels.R")
% sigstars <- apply(model.ass.pvalues.corrected[2:26], c(1,2), significancelevels) 
% 
% library("RColorBrewer")
% oddsratiocolours <- colorRampPalette(c("yellow", "white", "magenta"))
% library("gplots")
% heatmap.2((as.matrix(model.ass.oddsratios, rownames.force=TRUE)), col=oddsratiocolours, scale="none", na.rm=TRUE, key=TRUE, symkey=FALSE, density.info="none", trace="none", cexRow=0.5, xlab="", ylab="", Rowv=FALSE, Colv=FALSE, cexCol = 0.7, sepwidth=c(0.1,0.1), sepcolor="white", rowsep=c(1:56), colsep=c(1:56), na.color="gray94", cellnote=sigstars, notecol="black", main="Model data, n=209")
% @

\subsection{Multiple logistic regression models}

The goal is to compare several different models and their quality, and eventually compare them to clinical parameters that are currently used.\\
We first built a model with parameters that come out significant in the univariate analysis or have been described in the literature (genetic1). We can see that Trisomy12, NOTCH1 and BIRC3mono do not contribute to the model. There could be two reasons for this:\\
(1) They really do not contribute to the model\\
(2) There is a colinearity (or in factors, co-occurence) that did not show up on the associaton chart.\\

In order to see which one contributes most to the model, I built three models with only one of the them in:\\
\begin{itemize}
  \item genetic2 : NOTCH1
  \item genetic3: Trisomy12
  \item genetic4: BIRC3mono
\end{itemize}
You can see that NOTCH1 alone is not contributing to the model, Trisomy12 is contributing (and improving the AIC and Log Likelihood), and BIRC3mono contributes, but apparently towards MRD negativity, and with quite large variance(the number in brackets).

<<Summarized logistic regression, echo=FALSE, eval=TRUE>>=
model.genclinv6 <-subset(genclinv6, !is.na(genclinv6$MRD))
#calculate clones and CNAs as factors:
model.genclinv6$Subclones <- as.factor(ifelse(model.genclinv6$Subclones==0, "0", "1"))
#genclinv6$CNAs_cutoff6 <- as.factor(ifelse(genclinv6$Total_num_CNAs <= 6, "low", "high"))
#SUMMARIZED MODEL
fit.sum.gen1 <-glm(MRD ~ TP53_ALL+
                        ATM_bi+
                        BIRC3_mono+
                        Trisomy_12+
                        NOTCH1_mut+
                        SAMHD1_ALL
                        #SF3B1_mut
                        
                        , family=binomial(logit), data=model.genclinv6)
#summary(fit.sum.gen1)

fit.sum.gen2 <-glm(MRD ~TP53_ALL+
                        ATM_bi+
                        #BIRC3_mono+
                        #Trisomy_12+
                        NOTCH1_mut+
                        SAMHD1_ALL
                        #SF3B1_mut
                   
                        , family=binomial(logit), data=model.genclinv6)
#summary(fit.sum.gen2)

#model.genclinv6$TP53_mutdel <- as.factor(ifelse(model.genclinv6$TP53_mut=="1"|model.genclinv6$TP53_del=="1", "1", "0"))
fit.sum.gen3 <-glm(MRD ~ TP53_ALL+
                        ATM_bi+
                        #BIRC3_mono+
                        Trisomy_12+
                        #NOTCH1_mut+
                        SAMHD1_ALL
                        #SF3B1_mut
                        , family=binomial(logit), data=model.genclinv6)

fit.sum.gen4 <-glm(MRD ~ TP53_ALL+
                        ATM_bi+
                        BIRC3_mono+
                        SAMHD1_ALL
                        #SF3B1_mut
                        , family=binomial(logit), data=model.genclinv6)

# fit.sum.gen5 <-glm(MRD ~ TP53_ALL+
#                         ATM_bi+
#                         Trisomy_12+
#                         BIRC3_mono+
#                         SAMHD1_ALL
#                         , family=binomial(logit), data=model.genclinv6)
# 
# fit.sum.gen6 <-glm(MRD ~TP53_ALL+
#                         ATM_bi+
#                         #BIRC3_mono+
#                         #Trisomy_12+
#                         #NOTCH1_mut+
#                         SAMHD1_ALL
#                         #SF3B1_mut
#                         , family=binomial(logit), data=model.genclinv6)

model.genclinv6.vhmut <- subset(model.genclinv6, !is.na(vh_mutation_status))
fit.vhmut <-glm(MRD ~ vh_mutation_status
                        , family=binomial(logit), data=model.genclinv6.vhmut)
fit.vhmut_gen <-glm(MRD ~ vh_mutation_status+
                      TP53_ALL+
                        ATM_bi+
                        #BIRC3_mono+
                        Trisomy_12+
                        #NOTCH1_mut+
                        SAMHD1_ALL
                        , family=binomial(logit), data=model.genclinv6.vhmut)
fit.Binet <-glm(MRD ~ Binet
                        , family=binomial(logit), data=model.genclinv6)

@

<<stargazer,echo=FALSE, results=tex>>=
#RESULT TABLE in a nice format!
library(stargazer)
stargazer(fit.sum.gen1,fit.sum.gen2, fit.sum.gen3,fit.sum.gen4, fit.Binet,fit.vhmut,fit.vhmut_gen, summary=FALSE, title="Multiple log regression, n=209", font.size="tiny", single.row=TRUE, column.labels=c("genetic1", "genetic2", "genetic3", "genetic4", "Binet", "vhmut", "vhmutgen"), model.numbers=FALSE, notes.align="l", digits=2)
@

\newpage
\subsection{Missclassification Error}
<<Missclassification Error, echo=FALSE, eval=TRUE>>=
#list of all models
logregmodels <- list(fit.sum.gen1, fit.sum.gen2, fit.sum.gen3, fit.sum.gen4, fit.Binet, fit.vhmut, fit.vhmut_gen)
modelnames <- c("fit.sum.gen1", "fit.sum.gen2","fit.sum.gen3","fit.sum.gen4","fit.Binet", "fit.vhmut", "fit.vhmut_gen")
#make empty dataframe for results
missclasserror<- data.frame(matrix(NA, nrow = length(logregmodels), ncol = 5))
colnames(missclasserror) <- c("model", "correct_MRD_neg","false_MRD_neg", "correct_MRD_pos", "false_MRD_pos") 
missclasserror$model <- c("genetic1", "genetic2", "genetic3", "genetic4", "Binet", "vhmut", "vhmutgen")
model.genclinv6[, c(54:61)] <- NA
for (i in 1:7){
if (i < 6){
model.genclinv6[53+i] <- predict(logregmodels[[i]], type="response")
model.genclinv6[58+i] <- ifelse(model.genclinv6[53+i] > 0.5, "MRD positive", "MRD negative")
missclasserror$correct_MRD_neg[i] <- table(model.genclinv6$MRD, model.genclinv6[,58+i])[1]
missclasserror$false_MRD_neg[i] <- table(model.genclinv6$MRD, model.genclinv6[,58+i])[2]
missclasserror$correct_MRD_pos[i] <- table(model.genclinv6$MRD, model.genclinv6[,58+i])[4]
missclasserror$false_MRD_pos[i] <- table(model.genclinv6$MRD, model.genclinv6[,58+i])[3]
missclasserror$missclasserr[i] <- (missclasserror$false_MRD_pos[i]+missclasserror$false_MRD_neg[i])/209
}
if (i==6){
model.genclinv6.vhmut <- subset(model.genclinv6, !is.na(vh_mutation_status))
model.genclinv6.vhmut$predict_vhmut <- predict(logregmodels[[i]], type="response")
model.genclinv6.vhmut$class_vhmut <-ifelse(model.genclinv6.vhmut$predict_vhmut > 0.5, "MRD positive", "MRD negative")
missclasserror$correct_MRD_neg[i] <- table(model.genclinv6.vhmut$MRD, model.genclinv6.vhmut$class_vhmut)[1]
missclasserror$false_MRD_neg[i] <- table(model.genclinv6.vhmut$MRD, model.genclinv6.vhmut$class_vhmut)[2]
missclasserror$correct_MRD_pos[i] <- table(model.genclinv6.vhmut$MRD, model.genclinv6.vhmut$class_vhmut)[4]
missclasserror$false_MRD_pos[i] <- table(model.genclinv6.vhmut$MRD, model.genclinv6.vhmut$class_vhmut)[3]
missclasserror$missclasserr[i] <- (missclasserror$false_MRD_pos[i]+missclasserror$false_MRD_neg[i])/181
}
if (i==7){
model.genclinv6.vhmut$predict_vhmutgen <- predict(logregmodels[[i]], type="response")
model.genclinv6.vhmut$class_vhmutgen <-ifelse(model.genclinv6.vhmut$predict_vhmutgen > 0.5, "MRD positive", "MRD negative")
missclasserror$correct_MRD_neg[i] <- table(model.genclinv6.vhmut$MRD, model.genclinv6.vhmut$class_vhmutgen)[1]
missclasserror$false_MRD_neg[i] <- table(model.genclinv6.vhmut$MRD, model.genclinv6.vhmut$class_vhmutgen)[2]
missclasserror$correct_MRD_pos[i] <- table(model.genclinv6.vhmut$MRD, model.genclinv6.vhmut$class_vhmutgen)[4]
missclasserror$false_MRD_pos[i] <- table(model.genclinv6.vhmut$MRD, model.genclinv6.vhmut$class_vhmutgen)[3]
missclasserror$missclasserr[i] <- (missclasserror$false_MRD_pos[i]+missclasserror$false_MRD_neg[i])/181
}
}

names(model.genclinv6)[54:58] <- c("predict_genetic1", "predict_genetic2", "predict_genetic3", "predict_genetic4","predict_Binet")
 
missclasserror$unclassified <- c(0, 0, 0, 0, 0, 0, 29/209)
@

<<echo=FALSE, results=tex>>=
#RESULT TABLE in a nice format!
library(stargazer)
stargazer(missclasserror, summary=FALSE, title="Missclassification for summarized models", font.size="tiny", single.row=TRUE,column.sep.width="1p")
@
\subsubsection{Model probabilities}

The following graphs show the predicted probability for MRD positivity of the different models, with the x-axis showing the real MRD status. Note again that the final model only contains 181 data points.\\
The graph depicts the following variables (note:Not all of them are necessarily in the model depicted):\\
\begin{itemize}
  \item Trisomy12 is depicted by the shape of the points (cirle=0, square=1).
  \item vh mutation status is depicted by translucent points (translucent=mutated)
  \item ATM biallelic is depicted by light blue filling.
  \item SAMHD1 is depicted by green(0) and red(1) point outline.
  \item TP53 is depicted by point size (large=1)
\end{itemize}
The dashed red line shows the 0.5 line. Everything above is classified by the model as MRD positive, below is classified as MRD negative.
\newpage

<<fig=TRUE, echo=FALSE, width=9, height=5>>=
library(ggplot2)
ggplot(data=model.genclinv6)+
geom_point(aes(x=MRD, y=predict_genetic4, size=TP53_ALL, colour=SAMHD1_ALL, shape=Trisomy_12, fill=ATM_bi),position=position_jitter(w=0.3))+
  scale_alpha_manual(values=c(0.4, 1))+
  scale_size_manual(values=c(3,6))+
  scale_colour_manual(values=c("darkgreen", "red"))+
  scale_fill_manual(values=c("white", "lightblue"))+
  scale_shape_manual(values=c(21, 23))+
  theme_bw()+
  ggtitle("Model: genetic4\nPredicted probabilities for MRD positivity, n=209")+
geom_hline(y=0.5, linetype=3, colour="darkred", alpha=0.5)
@

<<fig=TRUE, echo=FALSE, width=10, height=5>>=
ggplot(data=model.genclinv6.vhmut)+
geom_point(aes(x=MRD, y=predict_vhmut, size=TP53_ALL, colour=SAMHD1_ALL, shape=Trisomy_12, alpha=vh_mutation_status, fill=ATM_bi),position=position_jitter(w=0.3))+
  scale_alpha_manual(values=c(0.4, 1))+
  scale_size_manual(values=c(3,6))+
  scale_colour_manual(values=c("darkgreen", "red"))+
  scale_fill_manual(values=c("white", "lightblue"))+
  scale_shape_manual(values=c(21, 23))+
  theme_bw()+
  ggtitle("Model: vhmut\nPredicted probabilities for MRD positivity, n=181")+
  ylim(c(0,1))+
  geom_hline(y=0.5, linetype=3, colour="darkred", alpha=0.5)
@

<<fig=TRUE, echo=FALSE, width=10,  height=5>>=
ggplot(data=model.genclinv6.vhmut)+
geom_point(aes(x=MRD, y=predict_vhmutgen, size=TP53_ALL, colour=SAMHD1_ALL, shape=Trisomy_12, alpha=vh_mutation_status, fill=ATM_bi),position=position_jitter(w=0.3))+
  scale_alpha_manual(values=c(0.4, 1))+
  scale_size_manual(values=c(3,6))+
  scale_colour_manual(values=c("darkgreen", "red"))+
  scale_fill_manual(values=c("white", "lightblue"))+
  scale_shape_manual(values=c(21, 23))+
  theme_bw()+
  ggtitle("Model: vhmutgen\nPredicted probabilities for MRD positivity, n=181")+
  geom_hline(y=0.5, linetype=3, colour="darkred", alpha=0.5)
@
\subsubsection{Conclusion model probabilities}
You can see that using only vh mutation status leads to a somewhat cloudy prediction with quite a lot of false positives. The genetic model (on the very top) as well as the combination of vh mutation status and genetic features lead to a more distinctive distribution, and fewer false positives.
\newpage
\subsection{Penalized models to determine variable importance}
\subsubsection{Logistic regression with Ridge}
Definition: Ridge regression shrinks regression coefficients for variables that do not contribute much to the model towards 0. Lambda is a tuning parameter that tells the model how strong this shrinkage should be.\\
I feed all significant univariate variables into the ridge regression.
<<Ridge logistic regression, echo=FALSE, eval=TRUE>>=
library(glmnet)
ridgevariables <- list("TP53_ALL", "ATM_bi", "Trisomy_12", "SAMHD1_ALL", "ATM_del", "BIRC3_del", "TP53_bi", "TP53_mut", "Trisomy_12", "MRD")
genclinv6_ridge <- model.genclinv6[colnames(model.genclinv6)%in% ridgevariables]
x=data.matrix(genclinv6_ridge[, -9])
y=genclinv6_ridge$MRD
ridge.model <- glmnet(x, y, family="binomial", alpha=0)
summary(ridge.model)
@
<<fig=TRUE, echo=FALSE>>=
plot(ridge.model)
@
\\We use cross validation to find the optimal lambda:\\
<<CV Ridge, echo=FALSE, eval=TRUE>>=
#Crossvalidate to find optimal lambda:
set.seed(1712)
cv.ridge= cv.glmnet(x, y, alpha=0, family="binomial")
@

<<fig=TRUE, echo=FALSE>>=
plot(cv.ridge)
@

<<CV Ridge lambda, echo=FALSE, eval=TRUE>>=
bestlambda=cv.ridge$lambda.min
bestlambda
@

<<Final Ridge model, echo=FALSE, eval=TRUE>>=
#built model with optimal lambda using the predict function to look at the coefficients
optimized.ridge.model <- predict(ridge.model, s=bestlambda, type="coefficient")
optimized.ridge.model <- as.data.frame(as.matrix(optimized.ridge.model))
colnames(optimized.ridge.model)[1]<- "coefficient_ridge"
optimized.ridge.model$variables <- row.names(optimized.ridge.model)
row.names(optimized.ridge.model) <- NULL
@

\subsubsection{Logistic regression with Lasso}
The Lasso is similar to the Ridge regression as it penalizes coefficients for variables that do not contribute to the model. In contrast to Ridge, it can make these coefficients exactly 0, thus eliminating them from the model.\\
<<Lasso logistic regression, echo=FALSE, eval=TRUE>>=
library(glmnet)
lasso.model <- glmnet(x, y, family="binomial", alpha=1)
summary(lasso.model)
@
<<Plot Lasso, fig=TRUE, echo=FALSE>>=
plot(lasso.model)
@

<<CV Lasso, echo=FALSE, eval=TRUE>>=
#Crossvalidate to find optimal lambda:
set.seed(1712)
cv.lasso= cv.glmnet(x, y, alpha=1, family="binomial")
@

<<fig=TRUE, echo=FALSE>>=
plot(cv.lasso)
@

<<CV Lasso lambda, echo=FALSE, eval=TRUE>>=
bestlambda=cv.lasso$lambda.min
bestlambda
@

<<FInal Lasso model, echo=FALSE, eval=TRUE>>=
optimized.lasso.model <- predict(lasso.model, s=bestlambda, type="coefficient")
optimized.lasso.model <- as.data.frame(as.matrix(optimized.lasso.model))
colnames(optimized.lasso.model)[1]<- "coefficient_lasso"
optimized.lasso.model$variables <- row.names(optimized.lasso.model)
row.names(optimized.lasso.model) <- NULL
@

\subsubsection{Compare Lasso and Ridge Regression Coefficients}
In this graph, you see the coefficients that were calculated by both models. On the x-axis, the lasso coefficient shows that we do not have any variables that were thrown on the vertical 0-line. On the y-axis, we can see that BIRC3\_del is close to 0. Bare in mind that the red dashed line is an artificial cut-off \emph{(as Chris about this)}. Note how most coefficients gather along the diagonal, which shows that we get similar results for both methods - usually a good sign for robust predictors.\\
<<fig=TRUE, eval=TRUE, echo=FALSE>>=
coefficients <- cbind(optimized.lasso.model, optimized.ridge.model)
coefficients <- coefficients[2:9, ]
library(ggplot2)
ggplot()+geom_point(data=coefficients, aes(x=coefficient_lasso, y=coefficient_ridge))+
geom_text(data=coefficients, aes(x=coefficient_lasso, y=coefficient_ridge, label = variables), vjust = 0.7, hjust = 1, size=3, col="darkblue")+
xlim(-1, 2)+
geom_hline(yintercept=0, alpha=0.5)+
geom_hline(yintercept=c(-0.5, 0.5), col="darkred", alpha=0.5, linetype="dashed")+
geom_vline(xintercept=0, alpha=0.5)
@
\subsubsection{Fazit penalized models}
The penalized models both give similar results (which is a good sign). A problem with penalized models is that they don't give us p-values, but we will need those for publication. \emph{To what extent the results should be used to inform some kind of hirarchy needs to be discussed with Chris.}

% % \subsection*{Find the best model with only important parameters (includes cutoff for ridge regression)}
% % <<Model with results from lasso and ridge, echo=FALSE, eval=TRUE>>=
% % variables_ridge_lasso_selected <- subset(coefficients, coefficient_lasso !=0)#& abs(coefficients$coefficient_ridge) > 0.4) 
% % genclin_ridge_lasso_selected <- genclinMRD[,colnames(genclinMRD)%in%variables_ridge_lasso_selected$variables] 
% % genclin_ridge_lasso_selected$MRD <- genclinMRD$MRD
% % 
% % system.time(best.subset.from.lasso <- bestglm(genclin_ridge_lasso_selected, family=binomial))
% % best.subset.from.lasso
% % fit_ridge_lasso_selected <- glm(MRD ~ ., family=binomial(logit), data=genclin_ridge_lasso_selected)
% % summary(fit_ridge_lasso_selected)
% % @
% % 
% % \subsection*{Elastic net and group selection (Hasties)}
% % Grouped selection: automatically include whole groups into the model if one variable amongst them is selected.(Do we want this?)

\section{Random Forest for variable importance}
We will use the variables of the multivariate regression model \emph{genetic3}:\\
\begin{itemize}
\item TP53\_ALL
\item ATM\_bi
\item Trisomy\_12
\item SAMHD1\_ALL
\end{itemize}
Here is our model:\\
<<RandomForest, echo=FALSE, eval=TRUE>>=
#produce data frame with only those variables
variablesgenetic3 <- c("TP53_ALL", "ATM_bi", "Trisomy_12", "SAMHD1_ALL", "MRD")
treegenetic <- model.genclinv6[colnames(model.genclinv6) %in% variablesgenetic3]
#produce strings for clarity:
for (i in c(1:5)){
treegenetic[,i] <- as.factor(paste(colnames(treegenetic[i]), treegenetic[,i], sep="_"))
}
 
library(randomForest)
set.seed(1712)
rf.genetic <- randomForest(MRD~., data=treegenetic, importance=TRUE, ntree=500, mtry=2, keep.forest = TRUE)
rf.genetic
@
\subsection{Determine performance and tuning the model}
We could potentially improve our model or shift its focus by changing the main tuning parameters:\\
\begin{itemize}
\item Number of trees
\item Weighted classes
\item Decision cutoff
\end{itemize}
\subsubsection{Number of trees}
<<echo=FALSE, fig=TRUE, width=8>>=
par(mfrow=c(1, 1))
plot(rf.genetic)
legend("topright", legend=c("OOB error", "MRD- classified as MRD+", "MRD+ classified as MRD-"),  fill=c("black", "green", "red"))
@ 
\\
Conclusion: The number of trees does not seem to play an important role, 500 should be sufficient.
 
\subsubsection{Weighted class}
The focus of our study is to find predictors for "MRD positive"(to give him/her access to the more expensive drug). There is cost of increasing true negative findings (real "MRD positives") as we will also generate more false positive findings ("MRD negatives" that are classified as positives).\\
We can incorporate class weights into the random forest classifier, thus making it more sensitive to find MRD positives. The resulting errors are shown below:\\
<<Model tuning WEIGHT, echo=FALSE, eval=TRUE>>=
truenegative <- NULL
falsenegative <- NULL
truepositive <- NULL
falsepositive <- NULL
oob.error <- NULL
weight <- NULL
for(i in c(1:5)){
weight[i] <- i
set.seed(1)
rf.genetic.weight <- randomForest(MRD~., data=treegenetic, importance=TRUE, classwt=c(1, i), ntree=500)
truenegative[i] <- rf.genetic.weight$confusion[4]/209
falsenegative[i] <- rf.genetic.weight$confusion[2]/209
truepositive[i] <- rf.genetic.weight$confusion[1]/209
falsepositive[i] <-  rf.genetic.weight$confusion[3]/209
oob.error[i] <- rf.genetic.weight$err.rate[600]
}
rf.errorrates <- as.data.frame(cbind(weight, truenegative, falsenegative, truepositive, falsepositive))
@
<<fig=TRUE, echo=FALSE, width=8>>=
library(ggplot2)
ggplot(rf.errorrates, aes(weight))+
geom_line(aes(y=truenegative, colour="MRD+ as MRD+"), size=1)+
geom_line(aes(y=falsenegative, colour="MRD- as MRD+"), size=1, lty=2)+
geom_line(aes(y=truepositive, colour="MRD- as MRD-"), size=1)+
geom_line(aes(y=falsepositive, colour="MRD+ as MRD-"), size=1, lty=2)+
geom_line(aes(y=oob.error, colour="oob.error"), size=1)+
scale_color_manual(values=c("darkolivegreen", "green","firebrick1", "firebrick4", "darkgrey"))+
ylab("Fraction of total")+
ggtitle("Weighted random forest model for genetic data")
@
\\
Here is an example for a model with weight slightly shifted towards finding more MRD positives:
<<Example, echo=FALSE, eval=TRUE>>=
rf.genetic.weights2 <- randomForest(MRD~., data=treegenetic, importance=TRUE, classwt=c(1, 2), ntree=500)
rf.genetic.weights2
@
\\
Conclusion: Introducing more MRD positive findings makes the model produce more false positives as well. Not very helpful...
 
\subsubsection{Cutoff selection}
We can vary the cutoff that is used in the single decision trees (that are combined in the forest model) such that there is an emphasis on putting patients into MRD+ groups.\\
 
<<Model tuning WEIGHT, echo=FALSE, eval=TRUE>>=
truenegative.cutoff <- NULL
falsenegative.cutoff <- NULL
truepositive.cutoff <- NULL
falsepositive.cutoff <- NULL
oob.error.cutoff <- NULL
rf.cutoff <- NULL
for(i in c(1:99)){
rf.cutoff[i] <- i*0.01
set.seed(1)
rf.genetic.cutoff <- randomForest(MRD~., data=treegenetic, importance=TRUE, cutoff=c(rf.cutoff[i], 1-rf.cutoff[i]), ntree=200)
truenegative.cutoff[i] <- rf.genetic.cutoff$confusion[4]/209
falsenegative.cutoff[i] <- rf.genetic.cutoff$confusion[2]/209
truepositive.cutoff[i] <- rf.genetic.cutoff$confusion[1]/209
falsepositive.cutoff[i] <-  rf.genetic.cutoff$confusion[3]/209
oob.error.cutoff[i] <- rf.genetic.cutoff$err.rate[200]
}
rf.errorrates.cutoff <- as.data.frame(cbind(rf.cutoff, truenegative.cutoff, falsenegative.cutoff, truepositive.cutoff, falsepositive.cutoff))
@
<<fig=TRUE, echo=FALSE, width=9>>=
library(ggplot2)
ggplot(rf.errorrates.cutoff, aes(rf.cutoff))+
geom_line(aes(y=truenegative.cutoff, colour="MRD+ as MRD+"), size=1)+
geom_line(aes(y=falsenegative.cutoff, colour="MRD- as MRD+"), size=1, lty=2)+
geom_line(aes(y=truepositive.cutoff, colour="MRD- as MRD-"), size=1)+
geom_line(aes(y=falsepositive.cutoff, colour="MRD+ as MRD-"), size=1, lty=2)+
geom_line(aes(y=oob.error.cutoff, colour="oob.error"), size=1)+
scale_color_manual(values=c("darkolivegreen", "green","firebrick1", "firebrick4", "darkgrey"))+
ylab("Fraction of total no of patients")+
ggtitle("random forest model with CUTOFF for genetic data")
@
\\
Conclusion: The model seems to be pretty stable for a cutoff between 0.5 and 0.75 and gets messy afterwards, so a change in cutoff is not advisable.
\subsection{Random Forest with vhmutation status}
<<RandomForest, echo=FALSE, eval=TRUE>>=
#produce data frame with only those variables
variablesvhmut_gen <- c("TP53_ALL", "ATM_bi", "Trisomy_12", "SAMHD1_ALL", "vh_mutation_status", "MRD")
treevhmut <- model.genclinv6[colnames(model.genclinv6) %in% variablesvhmut_gen]
treevhmut <- subset(treevhmut, !is.na(treevhmut$vh_mutation_status))
#produce strings for clarity:
for (i in c(1:5)){
treevhmut[,i] <- as.factor(paste(colnames(treevhmut[i]), treevhmut[,i], sep="_"))
}
 
library(randomForest)
set.seed(1712)
rf.vhmut <- randomForest(MRD~., data=treevhmut, importance=TRUE, ntree=500, mtry=2, keep.forest = TRUE)
rf.vhmut
@
\section{Estimating error and variation of Random forest}
To estimate error and variaton of the model, I devide our dataset at random 1:10 \emph{(ask Chris about this)} into a a training set and a test set. I then train a model on the training set and check it's performance on the test set. This process is repeated 100 times.
\subsection{Repeated random sub-sampling}
The next figure shows how the different errors vary when choosing random subsets for training the model\\
<<Repeated random subsampling 1:1, echo=FALSE, eval=TRUE >>=
#simple subsampling:
source("/home/andreas/suska/work/01_HICF1/HICF1_sub1/trunk/HICF_predictivemodel/HICF1_randomforest/rfcv_MRD.R")
modelperformance.genetic <- rfcv_MRD(treegenetic)
@
<<fig=TRUE, echo=FALSE, width=9>>=
require(reshape2)
modelperformance.genetic.sum <- melt(modelperformance.genetic, id.vars=c("model.no"))
modelperformance.genetic.sum$variable <- as.factor(modelperformance.genetic.sum$variable)
 
ggplot(modelperformance.genetic.sum, aes(x=variable, y=value))+
 geom_boxplot(colour=c("firebrick4", "green",  "darkolivegreen", "firebrick1","darkgrey"), outlier.colour = "white")+
 geom_point(position = position_jitter(w = 0.1), alpha=0.02)+
   ylab("Fraction of total no of patients in test set")+
   ggtitle("Repeated random sub-sampling for genetic data,\nnrepeat=1000")+
   theme_bw(base_size = 12, base_family = "")
@
 
\subsection{ROC comparison of different models}
<<ROC construction, echo=FALSE, eval=TRUE>>=
predict.rf <- as.data.frame(predict(rf.genetic, type = "prob"))
names(predict.rf) <- c("probMRDneg" , "probMRDpos")
 
#for random forest model
TruePositiveRate.rf <- NULL
FalsePositiveRate.rf <-NULL
FalseNegativeRate.rf <- NULL
TrueNegativeRate.rf <- NULL
for (i in 1:1000){
#get classes for these probabilities with threshold
predict.rf$class <- as.factor(ifelse(predict.rf$probMRDneg > i*0.001, "MRD negative", "MRD positive"))
confusion <- table(predict.rf$class, treegenetic$MRD)
#Probability that someone is predicted positive(MRD-), given that someone is negative(MRD+)
FalsePositiveRate.rf[i] <- confusion[3]/(confusion[3]+confusion[4])
#Probability that someone is predicted positive, given that someone is positive
TruePositiveRate.rf[i] <- confusion[1]/(confusion[1]+confusion[2])
#Probability that someone is predicted negative(MRD+), given that someone is positive(MRD-)
FalseNegativeRate.rf[i] <- confusion[2]/(confusion[2]+confusion[1])
#Probabilit that someone is predicted negative(MRD+), given that someone is negative
TrueNegativeRate.rf[i] <- confusion[4]/(confusion[4]+confusion[3])
}

#for random forest model VHMUTATION+GENETICS
#predict probability for response (not a 1, 0 variable!)
#produce data frame with only those variables
#predict probability for response (not a 1, 0 variable!)
variablesvhmut_gen <- c("TP53_ALL", "ATM_bi", "Trisomy_12", "SAMHD1_ALL", "vh_mutation_status", "MRD")
treevhmut <- model.genclinv6[colnames(model.genclinv6) %in% variablesvhmut_gen]
treevhmut <- subset(treevhmut, !is.na(treevhmut$vh_mutation_status))
#produce strings for clarity:
library(randomForest)
set.seed(1712)
rf.vhmut <- randomForest(MRD~., data=treevhmut, importance=TRUE, ntree=500, mtry=2, keep.forest = TRUE)

for (i in c(1:5)){
treevhmut[,i] <- as.factor(paste(colnames(treevhmut[i]), treevhmut[,i], sep="_"))
}
predict.rfvh <- as.data.frame(predict(rf.vhmut, type = "prob"))
names(predict.rfvh) <- c("probMRDneg" , "probMRDpos")
 

TruePositiveRate.rfvh <- NULL
FalsePositiveRate.rfvh <-NULL
FalseNegativeRate.rfvh <- NULL
TrueNegativeRate.rfvh <- NULL
for (i in 1:1000){
#get classes for these probabilities with threshold
predict.rfvh$class <- as.factor(ifelse(predict.rfvh$probMRDneg > i*0.001, "MRD negative", "MRD positive"))
confusion <- table(predict.rfvh$class, treevhmut$MRD)
#Probability that someone is predicted positive(MRD-), given that someone is negative(MRD+)
FalsePositiveRate.rfvh[i] <- confusion[3]/(confusion[3]+confusion[4])
#Probability that someone is predicted positive, given that someone is positive
TruePositiveRate.rfvh[i] <- confusion[1]/(confusion[1]+confusion[2])
#Probability that someone is predicted negative(MRD+), given that someone is positive(MRD-)
FalseNegativeRate.rfvh[i] <- confusion[2]/(confusion[2]+confusion[1])
#Probabilit that someone is predicted negative(MRD+), given that someone is negative
TrueNegativeRate.rfvh[i] <- confusion[4]/(confusion[4]+confusion[3])
}
#for logregression model
predict.logreg <- as.data.frame(predict(fit.sum.gen1, type = "response"))
names(predict.logreg) <- "probMRDneg"
TruePositiveRate.logreg <- NULL
FalsePositiveRate.logreg <-NULL
FalseNegativeRate.logreg <- NULL
TrueNegativeRate.logreg <- NULL
for (i in 1:1000){
#get classes for these probabilities with threshold
predict.logreg$class <- as.factor(ifelse(predict.logreg$probMRDneg < i*0.001, "MRD negative", "MRD positive"))
confusion <- table(predict.logreg$class, treegenetic$MRD)
#Probability that someone is predicted positive(MRD-), given that someone is negative(MRD+)
FalsePositiveRate.logreg[i] <- confusion[3]/(confusion[3]+confusion[4])
TruePositiveRate.logreg[i] <- confusion[1]/(confusion[1]+confusion[2])
#Probability that someone is predicted negative(MRD+), given that someone is positive(MRD-)
FalseNegativeRate.logreg[i] <- confusion[2]/(confusion[2]+confusion[1])
#Probabilit that someone is predicted negative(MRD+), given that someone is negative
TrueNegativeRate.logreg[i] <- confusion[4]/(confusion[4]+confusion[3])
}
 
#for vh mutation model
model.genclinv6.vhmut <- subset(model.genclinv6, !is.na(vh_mutation_status))
predict.vhmut <- as.data.frame(predict(fit.vhmut, type = "response"))
names(predict.vhmut) <- "probMRDneg"
TruePositiveRate.vhmut <- NULL
FalsePositiveRate.vhmut <-NULL
FalseNegativeRate.vhmut <- NULL
TrueNegativeRate.vhmut <- NULL
for (i in 1:1000){
#get classes for these probabilities with threshold
predict.vhmut$class <- as.factor(ifelse(predict.vhmut$probMRDneg < i*0.001, "MRD negative", "MRD positive"))
confusion <- table(predict.vhmut$class, model.genclinv6.vhmut$MRD)
#Probability that someone is predicted positive(MRD-), given that someone is negative(MRD+)
FalsePositiveRate.vhmut[i] <- confusion[3]/(confusion[3]+confusion[4])
TruePositiveRate.vhmut[i] <- confusion[1]/(confusion[1]+confusion[2])
#Probability that someone is predicted negative(MRD+), given that someone is positive(MRD-)
FalseNegativeRate.vhmut[i] <- confusion[2]/(confusion[2]+confusion[1])
#Probabilit that someone is predicted negative(MRD+), given that someone is negative
TrueNegativeRate.vhmut[i] <- confusion[4]/(confusion[4]+confusion[3])
}

#for vh mutation + genetics model
model.genclinv6.vhmut <- subset(model.genclinv6, !is.na(vh_mutation_status))
predict.vhmut_gen <- as.data.frame(predict(fit.vhmut_gen, type = "response"))
names(predict.vhmut_gen) <- "probMRDneg"
TruePositiveRate.vhmut_gen <- NULL
FalsePositiveRate.vhmut_gen <-NULL
FalseNegativeRate.vhmut_gen <- NULL
TrueNegativeRate.vhmut_gen <- NULL
for (i in 1:1000){
#get classes for these probabilities with threshold
predict.vhmut_gen$class <- as.factor(ifelse(predict.vhmut_gen$probMRDneg < i*0.001, "MRD negative", "MRD positive"))
confusion <- table(predict.vhmut_gen$class, model.genclinv6.vhmut$MRD)
#Probability that someone is predicted positive(MRD-), given that someone is negative(MRD+)
FalsePositiveRate.vhmut_gen[i] <- confusion[3]/(confusion[3]+confusion[4])
TruePositiveRate.vhmut_gen[i] <- confusion[1]/(confusion[1]+confusion[2])
#Probability that someone is predicted negative(MRD+), given that someone is positive(MRD-)
FalseNegativeRate.vhmut_gen[i] <- confusion[2]/(confusion[2]+confusion[1])
#Probabilit that someone is predicted negative(MRD+), given that someone is negative
TrueNegativeRate.vhmut_gen[i] <- confusion[4]/(confusion[4]+confusion[3])
}
@
 
<<ROC,echo=FALSE, width=9>>=
ROC.data <- as.data.frame(cbind(FalsePositiveRate.logreg, TruePositiveRate.logreg, TrueNegativeRate.logreg, FalseNegativeRate.logreg, FalsePositiveRate.rf, TruePositiveRate.rf, TrueNegativeRate.rf, FalseNegativeRate.rf, FalsePositiveRate.vhmut, TruePositiveRate.vhmut, TrueNegativeRate.vhmut, FalseNegativeRate.vhmut, FalsePositiveRate.vhmut_gen, TruePositiveRate.vhmut_gen, TrueNegativeRate.vhmut_gen, FalseNegativeRate.vhmut_gen, FalsePositiveRate.rfvh, TruePositiveRate.rfvh, TrueNegativeRate.rfvh, FalseNegativeRate.rfvh))
#ROC.data[is.na(ROC.data)] <- 0

# png("ROC.png")
# source("/home/andreas/suska/work/X_usefulcode/Rfunctions/multiplotfunction.R")
# 
# Positives <- ggplot(data=ROC.data)+
#   geom_line(aes(x=FalsePositiveRate.logreg, y=TruePositiveRate.logreg), colour="blue")+
#   geom_line(aes(x=FalsePositiveRate.rf, y=TruePositiveRate.rf), colour="red")+
#   geom_point(aes(x=FalsePositiveRate.vhmut, y=TruePositiveRate.vhmut), data=ROC.data, colour="green", size=10)+
#   geom_line(aes(x=FalsePositiveRate.vhmut_gen, y=TruePositiveRate.vhmut_gen), colour="purple")+
#   geom_line(aes(x=FalsePositiveRate.rfvh, y=TruePositiveRate.rfvh), colour="orange")+
#   theme_bw(base_size = 12, base_family = "")+geom_abline(intercept=0, slope=1, linetype=3, alpha=0.5)+
#   ggtitle("blue=genetic, red=random forest genetic, green=vhmutation")+
#   xlim(c(0,1))+
#   ylim(c(0,1))+
#   xlab("False Positive Rate")+
#   ylab("True Positive Rate")
# 
# 
# Negatives <- ggplot(data=ROC.data)+geom_line(aes(x=FalseNegativeRate.logreg, y=TrueNegativeRate.logreg),colour="blue")+
#   geom_line(aes(x=FalseNegativeRate.rf, y=TrueNegativeRate.rf), colour="red")+
#   geom_point(aes(x=FalseNegativeRate.vhmut, y=TrueNegativeRate.vhmut), colour="green", size=10)+
#   geom_line(aes(x=FalseNegativeRate.vhmut_gen, y=TrueNegativeRate.vhmut_gen), colour="purple")+
#   geom_line(aes(x=FalseNegativeRate.rfvh, y=TrueNegativeRate.rfvh), colour="orange")+
#   theme_bw(base_size = 12, base_family = "")+geom_abline(intercept=0, slope=1, linetype=3, alpha=0.5)+
#   xlim(c(0,1))+
#   xlab("False Negative Rate")+
#   ylab("True Negative Rate")
#   
# multiplot(Positives, Negatives)
# dev.off()
@
\includegraphics{ROC.png}
\\
Conclusion:\\
(1) The log regression model does better than the vhmutation model as it is more specific (still not very good though, it is supposed to hug the top right corner more).\\
(2) The random forest is still doing some really funny things, probably because it is highly overfitted to our data Apparently, calculating a ROC for random forests without deviding into train and test set is highly overoptimistic...


% % 
% % 
% % 
% % \subsection*{Best subset selection}
% % Variables that are important from Univariate Analysis (including trends)
% % TP53_All
% % TP53_morethan5VAF
% % ATM_ALL
% % ATM_del
% % BIRC3_del
% % ATM_biallelic
% % vh_mutation_status
% % 
% % <<Best subset selection, echo=FALSE, eval=TRUE>>=
% % 
% % library(bestglm)
% % #UNCORRECTED
% % #take significant/trend variables from univariate analysis
% % variables_uncorrected_univariate <- subset(genclinv6.pvalues, p.value < 0.1)
% % 
% % genclin_univariates_selected <-genclinMRD[,colnames(genclinMRD)%in% row.names(variables_uncorrected_univariate)]
% % #take out clinical parameters
% % genclin_univariates_selected$WBC <- NULL
% % genclin_univariates_selected$ALC <- NULL
% % genclin_univariates_selected$vh_mutation_status <- NULL
% % 
% % x=genclin_univariates_selected
% % #x <- na.omit(x)
% % y=genclinMRD$MRD
% % Xy <- cbind(x, y)
% % row.names(Xy) <- NULL
% % 
% % best.subset.selection <- bestglm(Xy, family=binomial)
% % best.subset.selection
% % 
% % #CORRECTED
% % #take significant/trend variables from univariate analysis
% % variables_corrected_univariate <- subset(genclinv6.pvalues, corrected.p.value < 0.1)
% % 
% % genclin_univariates_corrected <-genclinMRD[,colnames(genclinMRD)%in% row.names(variables_corrected_univariate)]
% % #take out clinical parameters
% % genclin_univariates_corrected$vh_mutation_status <- NULL
% % 
% % x=genclin_univariates_corrected
% % #x <- na.omit(x)
% % y=genclinMRD$MRD
% % Xy <- cbind(x, y)
% % row.names(Xy) <- NULL
% % 
% % best.subset.corrected <- bestglm(Xy, family=binomial)
% % best.subset.corrected
% % @

\end{document}

